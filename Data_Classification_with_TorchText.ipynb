{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOem+M3ljU5Mdzecb9JPp4t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtrochepy/machine_learning/blob/main/Data_Classification_with_TorchText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Networks Course with PyTorch**\n",
        "\n",
        "**Instructor:** Omar Uriel Espejel Diaz\n"
      ],
      "metadata": {
        "id": "dcTBUxbN5BlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensors in PyTorch**\n",
        "\n",
        "Tensors are a key component for creating and training machine learning models, allowing operations such as matrix multiplication and element-wise multiplication on large data sets. They are also useful for tasks like image processing, where you can represent an image as a three-dimensional tensor of pixels.\n",
        "\n",
        "Tensors are super flexible and can be used for all kinds of data, not just images or numbers. You can use them for things like text data, where you can represent words as vectors or embeddings.\n",
        "\n",
        "By mastering tensors, you'll be able to tackle more complex deep learning problems and develop more sophisticated models.\n",
        "\n",
        "**Example of a layer with tensors**\n",
        "\n",
        "This example of a PyTorch layer that uses tensors to create the key building block in modern artificial intelligence, the attention layer in Transformer models.\n",
        "\n",
        "**Let's go step by step.**\n",
        "\n",
        "**1.1 Creating Tensors**\n",
        "\n",
        "**Import PyTorch.**\n"
      ],
      "metadata": {
        "id": "xDmAe33G5NJk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BRhUKpjJ49Eq"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's review the version of PyTorch we are using.**"
      ],
      "metadata": {
        "id": "2uLZexaW5pxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD-OyMRq5rcT",
        "outputId": "7c31d679-a8bd-4d2a-ab95-8557c4a0fe51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scalars, vectors, matrices, and tensors are mathematical concepts used in deep learning and other fields of science and engineering.\n",
        "\n",
        "A scalar is a unique numerical value, such as **3** or **5.7**.\n",
        "\n",
        "A vector is a one-dimensional array of numerical values, such as **[1, 2, 3]** or **[0.2, 0.5, 0.8]**.\n",
        "\n",
        "A matrix is a two-dimensional array of numerical values, such as **[[1, 2, 3], [4, 5, 6], [7, 8, 9]]** or **[[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]]**.\n",
        "\n",
        "A tensor is a multidimensional array of numerical values, which can be considered as a generalization of vectors and matrices.\n",
        "\n",
        "A scalar is a tensor of order 0, a vector is a tensor of the first order, and a matrix is a tensor of the second order. Higher-order tensors, such as a third-order tensor or a fourth-order tensor, can represent more complex data structures, such as images or videos.\n",
        "\n",
        "Here's a simple illustration:\n",
        "\n",
        "Scalar: **3**\n",
        "Vector: **[1, 2, 3]**\n",
        "Matrix: **[[1, 2], [3, 4], [5, 6]]**\n",
        "Tensor: **[[[1, 2], [3, 4]], [[5, 6], [7, 8]]]**\n",
        "\n",
        "We can represent these data structures with PyTorch. We can create tensors using different types of values. For example, random, zeros, or ones."
      ],
      "metadata": {
        "id": "53HUIrfm6yPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "escalar = torch.randn(1)\n",
        "vector = torch.zeros(1,10)\n",
        "matriz = torch.ones(2,2)\n",
        "\n",
        "matriz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3aFEKzj7O9r",
        "outputId": "840e0dba-1d15-431c-d33d-0efb76b3266d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But we can also represent structures with no common name:"
      ],
      "metadata": {
        "id": "Urw-goch7p28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t5 = torch.randn(5,2,3)\n",
        "\n",
        "t5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGKeROb77sGq",
        "outputId": "4b61e4ea-eae4-418c-ee36-a46cf21de727"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9547,  0.7273,  0.0539],\n",
              "         [ 1.0332,  0.5827,  0.3404]],\n",
              "\n",
              "        [[-0.2962,  0.0048,  0.5620],\n",
              "         [-1.6079,  0.8106,  1.5160]],\n",
              "\n",
              "        [[-0.5480, -1.2391,  0.4620],\n",
              "         [ 0.9818,  0.5620, -1.8923]],\n",
              "\n",
              "        [[-0.5486,  2.0911, -0.7131],\n",
              "         [-3.1374, -0.4316,  0.8957]],\n",
              "\n",
              "        [[ 0.4705,  1.5177,  1.2811],\n",
              "         [ 0.6595,  0.5111, -0.3676]]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create tensors with the values we want, not necessarily random ones."
      ],
      "metadata": {
        "id": "bc5JkgXj72Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[2,2], [3,3]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcJshyrc74lT",
        "outputId": "642d0338-e812-42bc-f198-45d6a57942d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 2],\n",
              "        [3, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Debugging operations with tensors**\n",
        "\n",
        "When working with tensors, and the operations turn out to be invalid, we will have these three most common problems:\n",
        "\n",
        "1. The size or shape.\n",
        "2. The datatype.\n",
        "3. The device on which the tensor is located.\n",
        "\n",
        "The shape tells you how the elements within the tensor are organized."
      ],
      "metadata": {
        "id": "eHcz_A5K8RhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"La shape de la matriz es {matriz.shape}\")\n",
        "print(f\"La shape de t5 es {t5.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsCEPTgb8ZKb",
        "outputId": "9dbe87a2-3839-4ed8-96f7-eb7ef2a42783"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La shape de la matriz es torch.Size([2, 2])\n",
            "La shape de t5 es torch.Size([5, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also know the dimension of a tensor."
      ],
      "metadata": {
        "id": "1PKOBgIa8kUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"La shape de la matriz es {matriz.ndim}\")\n",
        "print(f\"La shape de t5 es {t5.ndim}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxSuJ5ok8mb9",
        "outputId": "628b55a9-b74e-42c3-8db7-a014cfcaf9a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La shape de la matriz es 2\n",
            "La shape de t5 es 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors can have elements with different types. It's important to know what type we are using.\n",
        "\n",
        "The most common type is torch.float or torch.float32 (32-bit float). When we talk about bits, we are dealing with the size of the information needed to represent a number. In machine learning, we work with thousands of numbers, so choosing the ideal size is key.\n",
        "\n",
        "**The rule is:** lower-bit data types (i.e., less precise) are faster to compute but sacrifice accuracy (faster to compute, but less accurate).\n",
        "\n",
        "Normally, when we operate between tensors, PyTorch converts the tensors into compatible types, but it is important that we are aware of the type of the tensors to avoid future errors."
      ],
      "metadata": {
        "id": "wBoJ4IJV9BL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_float32 = torch.tensor([[3.1,3.2], [3.3,3.4]])\n",
        "matriz_uint64 = torch.tensor([[3,3], [3,3]])\n",
        "\n",
        "# matriz_float32.dtype, matriz_uint64.dtype\n",
        "\n",
        "(matriz_float32 + matriz_uint64).dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dguQI-U9Hu7",
        "outputId": "7617254e-0d0c-4d46-9af4-4aa860f7c3ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If necessary, we can use y = y.to(...) to convert tensors to different types."
      ],
      "metadata": {
        "id": "y1agKboD9TGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_uint64.to(torch.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohc6BYFe9U4k",
        "outputId": "c7e5f6a1-9e5c-4a5f-e366-1fcd1c853a71"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3.],\n",
              "        [3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We must take into account the device for which our tensor is prepared. We cannot operate with a tensor designed for GPU (CUDA) and one for CPU."
      ],
      "metadata": {
        "id": "ojvwXuJ19g0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_uint64.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPhP-VU99i2L",
        "outputId": "9cebe8d0-a0df-45ce-c000-1b1920ebc20a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We check if we have a GPU available with **cuda.is_available()**.\n",
        "\n",
        "CUDA is a parallel computing platform and an application programming interface (API) that allows us to leverage the power of GPUs for deep learning tasks. When we use CUDA, we can perform complex mathematical operations in parallel on the GPU, which can significantly accelerate the training and inference of machine learning models.\n",
        "\n",
        "By using CUDA, we can take advantage of the massive parallel processing capabilities of GPUs and train models much faster than we could using only the CPU. Google Colab allows us to use a GPU at no cost."
      ],
      "metadata": {
        "id": "E2DwuEtv94cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDnvtelZ99Vb",
        "outputId": "4033e69b-66f5-498b-ecc4-8eb8bbe27eb9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code, we will check if we have CUDA available and, if so, convert CPU tensors to CUDA and vice versa, while also changing the type.\n",
        "\n",
        "It will return an error because we cannot operate with tensors on different devices."
      ],
      "metadata": {
        "id": "uiteiKx0-Naz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  matriz_uint64_cuda = matriz_uint64.to(torch.device(\"cuda\"))\n",
        "\n",
        "  print(matriz_uint64_cuda, matriz_uint64_cuda.type())\n",
        "  print(matriz_uint64_cuda.to(\"cpu\", torch.float32))\n",
        "\n",
        "  # matriz_uint64_cuda + matriz_uint64"
      ],
      "metadata": {
        "id": "YmFa7aR4-QnT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 Interaction with NumPy**\n",
        "\n",
        "Convert the tensor to NumPy."
      ],
      "metadata": {
        "id": "IRpCWBAG-luD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(matriz.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snWr5F-k-owc",
        "outputId": "31ed387b-91d1-4863-f76d-ae980b31f1e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import NumPy."
      ],
      "metadata": {
        "id": "bgg0_PxZ-zv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "11TgXaH9-2Mj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we can also convert from NumPy to PyTorch, and the type is maintained."
      ],
      "metadata": {
        "id": "0yPNc7q7_EAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = np.ones(5)\n",
        "torch.from_numpy(vector).dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqNbKDym_Hib",
        "outputId": "f3c77e65-0c3e-45dd-d809-6a7d9c21bb9f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Operations with tensors**\n",
        "\n",
        "First, let's create some tensors in PyTorch:"
      ],
      "metadata": {
        "id": "Hxoxz3uF_XSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor of zeros with shape (3, 4)\n",
        "zeros_tensor = torch.zeros((3, 4))\n",
        "\n",
        "# create a tensor of ones with shape (3, 4)\n",
        "ones_tensor = torch.ones((3, 4))\n",
        "\n",
        "# create a tensor of random values with shape (2, 2)\n",
        "random_tensor = torch.randn((4))"
      ],
      "metadata": {
        "id": "mB5AFN_1_cRT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiuFXlVt_hAb",
        "outputId": "77db8785-bc14-4580-f006-fb90a74438f4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's perform \"element-wise\" operations:"
      ],
      "metadata": {
        "id": "fI9nXxej_t8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add two tensors element-wise\n",
        "added_tensor = zeros_tensor + ones_tensor\n",
        "\n",
        "# subtract two tensors element-wise\n",
        "subtracted_tensor = zeros_tensor - ones_tensor\n",
        "\n",
        "# multiply two tensors element-wise\n",
        "multiplied_tensor = zeros_tensor * ones_tensor\n",
        "\n",
        "# divide two tensors element-wise\n",
        "divided_tensor = random_tensor / ones_tensor"
      ],
      "metadata": {
        "id": "ZmyWCMFx_wck"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "divided_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ryFD3g4_82k",
        "outputId": "38811083-bafa-452f-eafb-f106a1bdc3d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0549, -0.9265, -0.2616, -0.7132],\n",
              "        [ 1.0549, -0.9265, -0.2616, -0.7132],\n",
              "        [ 1.0549, -0.9265, -0.2616, -0.7132]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix multiplication:"
      ],
      "metadata": {
        "id": "0hLiOtMfAEVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create two matrices\n",
        "matrix1 = torch.randn(2,3)\n",
        "matrix2 = torch.randn(3,2)\n",
        "\n",
        "# print(f\"matrix1 shape: {matrix1.shape}\")\n",
        "# print(f\"matrix2 shape: {matrix2.shape}\")\n",
        "\n",
        "# perform matrix multiplication\n",
        "torch.matmul(matrix1, matrix2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_XmWj4iAF5q",
        "outputId": "a14bb8b7-6d30-4de0-cc1f-ceaf226b78f3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are just some examples of the types of operations you can perform on PyTorch tensors. You can also perform other operations such as taking the transpose of a tensor, changing the shape of a tensor, and more.\n",
        "\n",
        "Always remember to pay attention to the shape and data types of your tensors when performing operations.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "The given text provides an in-depth understanding of tensors in PyTorch, how they are applied in machine learning models, and the various operations that can be performed with them. By mastering these foundational concepts, one can tackle complex deep learning problems and develop more advanced models. The translation covers a range of topics including tensor creation, debugging, interaction with NumPy, and specific operations. With practical examples and a clear focus on understanding the characteristics of tensors, this guide offers a valuable resource for anyone looking to delve into machine learning or deepen their understanding of PyTorch and its applications."
      ],
      "metadata": {
        "id": "cHviX1WkAXOE"
      }
    }
  ]
}