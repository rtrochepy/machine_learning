{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfEAbRjNMEbiXTY3R64ZGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtrochepy/machine_learning/blob/main/O_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Networks Course with PyTorch**\n",
        "\n",
        "Instructor: Omar Uriel Espejel Diaz"
      ],
      "metadata": {
        "id": "nDuPnDgYko-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With PyTorch, you can leverage the latest advances in artificial intelligence to create innovative solutions for a wide range of applications, from computer vision to natural language processing and more.\n",
        "\n",
        "It also has the support of a vibrant and supportive community of developers and researchers. This means that you will have access to a wealth of resources, tools, and knowledge that will help you stay at the forefront of AI research and development.\n",
        "\n",
        "You will be able to see what a relatively simple model looks like. However, this will always be the structure of a model, whether it's for vision, transformers for natural language processing, or reinforcement learning.\n",
        "\n",
        "In PyTorch, **nn.Module** is very important. It's a class that allows you to create, store, and manipulate all kinds of layers and neural network operations.\n",
        "\n",
        "Why is this great? It means that you can create complex models with many layers without having to worry about the details of each one. **nn.Module** takes care of all that for you, so you can focus on building your model and getting results.\n",
        "\n",
        "In summary, if you are working with PyTorch and building neural networks, **nn.Module** will be your new best friend.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vP7EmQgfkx2u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6PAqdl5Qkcnr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TextClassifier(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)\n",
        "    output, (hidden, cell) = self.rnn(embedded)\n",
        "    final_hidden = hidden[-1]\n",
        "    return self.fc(final_hidden)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's look at this code step by step:**\n",
        "\n",
        "1. We define a class called TextClassifier that is inherited from nn.Module.\n",
        "\n",
        "2. In the constructor, we define the layers of our model: an embedding layer, an LSTM layer with 2 layers and hidden_dim hidden units per layer, and a linear layer that maps the final hidden state to the output dimension.\n",
        "\n",
        "3. With the forward method, we first create an embedding with the input text using the embedding layer.\n",
        "\n",
        "4. Then we pass the embedded text through the LSTM layer and retrieve the final hidden state.\n",
        "\n",
        "5. Finally, we pass the final hidden state through the linear layer to get the output logits.\n",
        "\n",
        "To use this model, you can instantiate it like this:"
      ],
      "metadata": {
        "id": "zJTsHOg1l8ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "output_dim = 2\n",
        "\n",
        "model = TextClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)"
      ],
      "metadata": {
        "id": "i06BxDz9mFW8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqoPoXwPmH8O",
        "outputId": "a1b96e42-82de-4a3e-fd45-4a2fbdba5848"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextClassifier(\n",
              "  (embedding): Embedding(10000, 100)\n",
              "  (rnn): LSTM(100, 256, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we assume that we are doing binary classification, so **output_dim** is set to 2. If you are doing multi-class classification, you should set **output_dim** to the number of classes.\n",
        "\n",
        "Please note that you will need to define your own text preprocessing pipeline and tokenization scheme before you can train this model on your dataset.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "PyTorch offers powerful and flexible tools for creating complex models in various fields such as computer vision, natural language processing, and more. Its nn.Module class streamlines the creation and handling of neural network layers, allowing developers to focus on building models without being bogged down by the details. Moreover, with a strong community backing, PyTorch provides access to numerous resources and insights that keep you aligned with the cutting edge of AI research and development. Whether a novice or an expert, PyTorch provides the essentials to make AI modeling accessible and effective.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6ApY0wGkmlV0"
      }
    }
  ]
}